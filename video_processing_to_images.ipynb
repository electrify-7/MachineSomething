{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 1: Load the Video and Extract Frames\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Define paths\n",
    "dataset_path = 'path_to_your_dataset'\n",
    "output_path = 'path_to_output_frames'\n",
    "\n",
    "# Ensure output directory exists\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "# Subjects, angles, and lighting conditions\n",
    "subjects = [f'subject{i}' for i in range(1, 12)]  # 11 subjects\n",
    "angles = [f'angle{i}' for i in range(1, 19)]  # 18 angles\n",
    "light_settings = ['warm', 'cold', 'low', 'medium', 'bright']  # 5 lighting conditions\n",
    "\n",
    "# Loop through each subject, angle, and lighting condition\n",
    "for subject in subjects:\n",
    "    for angle in angles:\n",
    "        for lighting in light_settings:\n",
    "            # Define video file name\n",
    "            video_file = f'{subject}_{angle}_{lighting}.mp4'\n",
    "            video_path = os.path.join(dataset_path, subject, video_file)\n",
    "\n",
    "            # Check if the video file exists\n",
    "            if not os.path.exists(video_path):\n",
    "                print(f\"Video {video_file} not found, skipping...\")\n",
    "                continue\n",
    "\n",
    "            # Open video capture\n",
    "            cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "            frame_count = 0\n",
    "            success = True\n",
    "\n",
    "            # Create directory for the subject, angle, and lighting\n",
    "            frames_output_dir = os.path.join(output_path, subject, angle, lighting)\n",
    "            os.makedirs(frames_output_dir, exist_ok=True)\n",
    "\n",
    "            # Extract frames from video\n",
    "            while success:\n",
    "                success, frame = cap.read()  # Read one frame\n",
    "                if success:\n",
    "                    # Save each frame\n",
    "                    frame_file = os.path.join(frames_output_dir, f'frame_{frame_count:04d}.jpg')\n",
    "                    cv2.imwrite(frame_file, frame)\n",
    "                    frame_count += 1\n",
    "\n",
    "            cap.release()  # Release video capture\n",
    "            print(f\"Extracted {frame_count} frames from {video_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 2: Load Extracted Frames as a Dataset\n",
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def load_frames_from_directory(frames_dir, target_size=(224, 224)):\n",
    "    frames_list = []\n",
    "    for frame_file in sorted(os.listdir(frames_dir)):\n",
    "        frame_path = os.path.join(frames_dir, frame_file)\n",
    "        img = load_img(frame_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        frames_list.append(img_array)\n",
    "    return np.array(frames_list)\n",
    "\n",
    "# Example to load frames of one subject, angle, and lighting condition\n",
    "subject = 'subject1'\n",
    "angle = 'angle1'\n",
    "lighting = 'warm'\n",
    "frames_dir = os.path.join(output_path, subject, angle, lighting)\n",
    "\n",
    "frames_array = load_frames_from_directory(frames_dir)\n",
    "print(f\"Loaded {frames_array.shape[0]} frames, each of shape {frames_array.shape[1:]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: Prepare for Model Training\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "frames_array = frames_array.astype('float32') / 255.0\n",
    "\n",
    "# Assuming you have a model ready, you can train it as follows:\n",
    "# labels = ... # Your labels for the corresponding frames\n",
    "# model.fit(frames_array, labels, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 4: Working with Multiple Video Files (Batch Processing)\n",
    "\n",
    "video_dir = 'path_to_video_dataset'  # Directory containing video files\n",
    "for video_file in os.listdir(video_dir):\n",
    "    video_path = os.path.join(video_dir, video_file)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Process each video as before (extract frames, load them into arrays)\n",
    "    # You can append the resulting frames to a combined array for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
